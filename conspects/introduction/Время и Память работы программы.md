## O-нотация



### Зачем это нужно?

Казалось бы, что для оценки времени работы можно просто физически измерять время, которое программа работает на разных входных данных. Здесь есть достаточное количество минусов:

* время выполнения программы на разном железе может быть разным, а тестируется все на одном;
* чтобы измерить время, придется запустить сам алгоритм, но иногда приходится оценивать алгоритмы, требующие часы или даже дни работы;
* время будет учитывать какие-то вспомогательные операции, которые на самом деле в текущей оценке не нужны;
* Зачастую основной задачей программиста становится оптимизировать алгоритм, выполнение которого займёт тысячи лет, до какого-нибудь адекватного времени работы. Поэтому хотелось бы уметь предсказывать, сколько времени займёт выполнение алгоритма ещё до того, как мы его запустим.



### Как же посчитать?

Будем считать за одну операцию следующие (компьютер успевает выполнить $10^8$ таких операций за секунду, но иногда можно добиться и выполнения $10^9$ операций за секунду на быстрых процессорах, хотя на это не стоит рассчитывать):

* арифметические операции ($*$, $+$, $-$, $/$, битовые сдвиги);
* сравнение чисел;
* присваивание;

Мы можем попробовать точно оценить количество таких операций, которые выполняются в программе. Но в большинстве случаев такого подробного разбора всех действий не требуется. Если вы посчитаете, сколько операций сравнения происходит в разных квадратичных сортировках, то получите разные выражения, где главный член - это $N^2$, умноженное на некоторую константу плюс еще некоторая константа. 

Хочется придумать способ упростить эти формулы так, чтобы:

1) не нужно было учитывать много информации, не очень сильно влияющей на итоговое время;
2) легко было оценивать время работы разных алгоритмов для больших чисел;
3) легко было сравнивать алгоритмы на предмет того, какой из них лучше подходит для тех или иных входных данных.



### O-нотация

Для этого придумали **$O$-нотацию** - асимптотическое время работы вместо точного (часто его ещё называют асимптотикой).

Пусть $f(N)$ - это какая-то функция. Говорят, что алгоритм работает за $O(f(N))$, если существует число $C$, такое что алгоритм работает не более чем за $C \cdot f(N)$ операций. 

В таких обозначениях можно сказать, что

* Сортировка пузырьком работает за $O(N^2)$
* Сортировка подсчетом работает за $O(N + M)$
* Быстрая сортировка работает за $O(N \cdot logN)$

Это обозначение удобно тем, что оно короткое и понятное, а также оно не зависит от умножения на константу или прибавления константы. Если алгоритм работает за $O(N^2)$, то это может значить, что он работает за $N^2$, за $N^2 + 3$, за $\frac{N(N-1)}{2}$ или даже за $1000 \cdot N^2 + 1$ действие. 

Главное, что функция ведет себя как $N^2$, то есть при увеличении $N$ (в данном случае это длина массива) он увеличивается как некоторая квадратичная функция. Например, если увеличить $N$ в $10$ раз, время работы программы увеличится приблизительно в $100$ раз.

Поэтому все эти рассуждения про то, сколько операций в `swap` или считать ли отдельно присваивания, сравнения и циклы - отпадают. Как бы вы ни ответили на эти вопросы, они меняют ответ на константу, а значит асимптотическое время работы алгоритма никак не меняется.

## Примеры
```cpp
bool is_prime(int x) {
    for (int i = 2; i*i <= x; i++) {
        if (x % i == 0) return true;
    }
    return x > 1;
}

/*
    * O(sqrt(x))
    * так как максимальное значение i = sqrt(x) и внутри цикла выполняется только одна операция
*/
```


```cpp
long long cnt = 0;
for (int i = 0; i < n; i++) {
    // Выполнится n раз
    for (int j = 0; j < n; j++) {
        // Выполнится n раз
        for (int k = 0; k < n; k++) {
            // Выполнится n раз
            cnt++;
        }
    }
}

/*
    * n = 10      ~ 1000
    * n = 100     ~ 10^6 (1e6)
    * n = 1000    ~ 10^9 (1e9)
    * n = 2000    ~ 8*10^9 (8e9)
    * Очевидно, что асимптотика составляет O(n^3), так как количество операций = n * n * n

*/
```


```cpp
long long cnt = 0;
for (int i = 0; i < n; i++) {
    // Выполнится n раз
    for (int j = 0; j < n; j++) {
        // Выполнится n раз
        for (int k = j; k < n; k++) {
            // Выполнится n-j раз
            cnt++;
        }
    }
}

/*
    * n = 10      ~ 550
    * n = 100     ~ 5e5
    * n = 1000    ~ 5e8
    * n = 2000    ~ 4e9
    * Таким образом, асимптотика составляет O(n^3), домашним заданием будет доказать это формулами (посчитать количество операций).
/*
```